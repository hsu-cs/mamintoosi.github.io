---- اطلاعات درس ----

شماره: ۴۰۹۵۷.۲
عنوان: یادگیری تقویتی
عنوان انگلیسی: Reinforcement Learning
مقطع: کارشناسی ارشد
گرایش: هوش مصنوعی
واحد: ۳
نوع: نظری
دسته: تخصصی
پیش‌نیاز: یادگیری ژرف
هم‌نیاز: --
متولی: گروه هوش مصنوعی
طراح:‌ محمدحسین رهبان
آخرین تصویب: ۱۳۹۸/۰۱/۰۱

قالب: قالب درس
----------------------------


===== اهداف درس =====

امروزه در طیف وسیعی از مسائل در دنیای واقعی امکان ارائه بازخورد لحظه‌ای و جزئی برای آموزش عامل‌های هوشمند وجود ندارد. رویکرد متداول در این حالات یادگیری تقویتی است. از جمله چالش‌های این حوزه، تنک بودن بازخوردها، زمان و تعداد نمونه‌های بالای مورد نیاز برای آموزش این عامل‌ها، بعد بالای مشاهدات دریافت شده از محیط، و همینطور تطبیق‌پذیری سریع با محیط‌های جدید است. در این درس این موارد را مورد بررسی قرار می‌دهیم.

===== ریز مواد =====

  - **مفهوم Multi-armed Bandits**
  - **مدل‌های تصمیم مارکف محدود ‌MDP و POMDP**
  - **معادلات Bellman، ارزیابی سیاست و بهبود آن**
     * برنامه‌ریزی پویا
     * تکرار سیاست
     * تکرار ارزش 
     * بهبود سیاست 
  - **روش‌های Monte Carlo**
     * پیش‌بینی
     * کنترل
     * نمونه‌برداری وزن‌دار (Importance Sampling)
  - **یادگیری اختلاف زمانی (Temporal Difference)**
     * یادگیری on-policy و off-policy
     * روش Q-Learning
     * روش SARSA 
  - **یادگیری تقویتی معکوس**
  - **یادگیری تقلیدی** 
  - **روش‌های Bootstrap با n گام و لامبدا TD** 
  - **روش‌های تخمین**
     * روش Deep Q-Learning
     * روش Deep Double Q-Learning
  - **روش Policy Gradient**
     * روش‌های کاهش واریانس گرادیان 
     * الگوریتم REINFORCE
  - **روش‌های نوین بهینه‌سازی** 
     * روش ناحیه مطمئن TRPO
     * روش بهینه‌سازی سیاست مبدائی PPO
  - **روش‌های نوین Off-Policy**
     * روش DDPG
     * روش ‌‌Soft Actor Critic یا SAC
  - **روش‌های مبتنی بر مدل**
     * روش‌های برنامه‌ریزی 
     * روش Model Predictive Control
     * روش‌ بهینه‌سازی مبتنی بر Cross-entropy
     * درخت جستجوی Monte Carlo 
     * روش Backpropagation Through Time
     * روش‌های مبتنی بر Ensemble 
  - **یادگیری تقویتی در بینایی ماشین**
  - **روش‌های یادگیری نمایش**
     * روش CURL
  - **روش‌های فرایادگیری (Meta Learning)**
     * روش MAML
     * روش PEARL 
     * روش CaDM
     * روش MetaCURE
  - **شکل‌دهی به سود (Reward Shaping)**
  - **روش‌های ناتنیده کردن اکتشاف و بهره‌برداری**
  - **روش‌های چند عاملی**

===== ارزیابی =====

  * تمرین‌ها: ۳۵ درصد
  * ارائه مقاله: ۱۰ درصد
  * امتحان کوتاه: ۱۰ درصد
  * امتحان میان‌ ترم: ۲۰ درصد
  * امتحان پایان‌ ترم: ۲۵ درصد 

===== مراجع =====

<div :en>
  - Richard S. Sutton, Andrew G. Barto, “Reinforcement Learning,” 2nd Edition, MIT Press, 2020.
  - Alexander Zai, Brandon Brown, “Deep Reinforcement Learning in Action,” Manning, 2020.
</div>
