
---- اطلاعات درس ----

شماره: ۴۰۷۱۹
عنوان: یادگیری ژرف
عنوان انگلیسی: Deep learning
مقطع: کارشناسی ارشد
گرایش: هوش‌مصنوعی
واحد: ۳
نوع: نظری
دسته: تخصصی
پیش‌نیاز: یادگیری ماشین
هم‌نیاز: --
متولی: گروه هوش مصنوعی
طراح:‌ مهدیه سلیمانی
آخرین تصویب: 

قالب: قالب درس
----------------------------


===== اهداف درس =====

اين درس به حوزه‌ای از يادگيری ماشین تحت عنوان يادگيری ژرف که در سال‌های اخير بسيار موردتوجه قرار گرفته و به عملکرد چشم‌گيری در بسياری از کاربردها دست‌يافته است خواهد پرداخت. در طول اين درس ابتدا مفاهیم اولیه، نظیر شبکه‌های  عصبی چندلایه، قدرت مدلسازی این شبکه‌ها و نحوه‌ی آموزش آن‌ها بحث می‌شود. سپس آشنایی با معماری‌های اصلی نظیر شبکه‌های CNN و RNN صورت خواهد گرفت. همچنین پيشرفت‌هایی که در طراحی، بهینه‌سازی، بهبود تعمیم‌پذیری و نحوه‌ی آموزش شبکه‌ها در حوزه يادگيری ژرف صورت گرفته است معرفی می‌شود. مدل‌های مولد نیز به عنوان یکی از شاخه‌های مهم مورد بررسی قرار خواهند گرفت. به‌علاوه به تعدادی از شبکه‌های ژرف معروف که طی سال‌های اخير معرفی شده‌اند، اشاره خواهد شد. در طول درس به کاربردهای مهم شبکه‌های معرفی شده به خصوص در زمینه‌های بینایی ماشین و پردازش زبان طبیعی اشاره خواهد شد. 

===== ریز مواد =====

  - ** مقدمه و معرفی شبکه‌های عصبی مصنوعی ** 
  - ** پرسپترون چند لايه (Multi-layer Perceptron) **
    * MLP به عنوان تقريب‌زننده عمومی (Universal approximator)
  - ** الگوريتم انتشار رو به عقب‌ خطا (Error back propagation) **
  - ** بهينه‌سازی در شبکه‌های ژرف **
    * مروری بر بهینه‌سازی محدب
    * معرفی انواع روشهای SGD، Momentum، RMS Prop، Adams و …
  - ** تکنيک‌هايی در آموزش، طراحی و تعميم‌پذيری شبکه‌های ژرف **
    * معرفی تکنیک‌های بهبود تعمیم‌پذیری نظیر regularization، dropout، data augmentation 
    * هنجارسازی بسته‌ای (Batch Normalization)
    * انتخاب توابع فعالیت (activation function)، مقداردهی اولیه وزنها، هنجارسازی ورودی و …
  - ** شبکه‌های عصبی کانولوشنی (Convolutional Neural Networks) **
    * لایه‌های convolution و pooling
    * معماریهای معروف شبکه‌های CNN
    * کاربردهای مختلف شبکه‌های CNN
  - ** شبکه‌های عصبی بازگردنده (Recurrent Neural Networks) **
    * مدل‌سازی دنباله‌ها
    * حافظه‌های بلند کوتاه مدت (Long Short Term Memories)
    * شبکه‌های توجه (Attention Networks)
    * مدل‌سازی زبانی (Language Modeling) با استفاده از شبکه‌های RNN
    * کاربرد‌های دیگر شبکه‌های RNN در زمینه‌های مختلف نظیر پردازش زبان طبیعی (Natural Language Processing)
  - ** معماری تبدیل کننده (Transformer) **
  - ** شبکه‌های جمع-ضرب (Product-Sum) **
  - ** مدل‌های مولد (Generative Models) **
    * مدلهای Autoregressive
    * خودکدگذار وردشی (Variational)
    * شبکه‌های مولد حريفانه (Generative Adversarial Networks)
    * مدل‌های مولد مبتنی بر جریان (Flow based)
  - ** يادگيری تقويتی ژرف (Deep Reinforcement Learning) **
    * یادگیری تقویتی ژرف با استفاده از توابع Q (Q function)
    * رویکرد گرادیان سیاست (Policy Gradient)
    * رویکرد بازیگر-نقاد (Actor Critic)
  - ** نمونه‌های خصمانه (Adversarial)‌ و مقاومت شبکه‌های ژرف به نمونه‌های خصمانه **
  - ** مباحث پیشرفته **
    * شبکه‌های دوگان  و یادگیری دوگان (Dual Learning)
    * شبکه‌های کانولوشن گرافی
    * یادگیری خودنظارتی (Self-supervised)


===== ارزیابی =====

  * تمرين: ۳۰٪
  * ميان‌ترم: ۲۰٪
  * پايان‌ترم: ۳۰٪
  * آزمون‌های کوتاه: ۱۰٪
  * پروژه يا کار تحقيقاتی: ۱۰٪

===== مراجع =====

<div :en>
  - Ian Goodfellow, Yoshua Bengio and Aaron Courville, Deep Learning, Book in preparation for MIT Press, 2016.
  - Michael Nielsen, Neural networks and deep learning, Preprint, 2016.
</div>