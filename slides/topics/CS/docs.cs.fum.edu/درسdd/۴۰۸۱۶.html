<!DOCTYPE html>
<html lang="fa" dir="rtl" class="no-js">

<!-- Mirrored from docs.ce.sharif.edu/درس/۴۰۸۱۶ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 08 Feb 2023 17:37:37 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8" />
    <title>امنیت و حریم خصوصی در یادگیری ماشین [ دانشکده علوم ریاضی ]</title>
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>
    <meta name="generator" content="DokuWiki"/>
<meta name="theme-color" content="#008800"/>
<meta name="robots" content="index,follow"/>
<meta name="keywords" content="درس,۴۰۸۱۶"/>
<link rel="search" type="application/opensearchdescription+xml" href="../lib/exe/opensearch.php" title=" دانشکده علوم ریاضی "/>
<link rel="start" href="../index.html"/>
<link rel="contents" href="%db%b4%db%b0%db%b8%db%b1%db%b6decf.html?do=index" title="نقشه سایت"/>
<link rel="manifest" href="../lib/exe/manifest.php"/>
<link rel="alternate" type="text/html" title="HTML ساده" href="../_export/xhtml/%d8%af%d8%b1%d8%b3/%db%b4%db%b0%db%b8%db%b1%db%b6.html"/>
<link rel="alternate" type="text/plain" title="نشانه‌گذاری ویکی" href="../_export/raw/%d8%af%d8%b1%d8%b3/%db%b4%db%b0%db%b8%db%b1%db%b6.txt"/>
<link rel="canonical" href="%db%b4%db%b0%db%b8%db%b1%db%b6.html"/>
<link rel="stylesheet" type="text/css" href="../lib/exe/cssaa19.css?t=docs&amp;tseed=6edb3bd901a41874a3c4990e4362952b"/>
<link type="text/css" rel="stylesheet" href="../lib/plugins/datatables/assets/datatables/media/css/jquery.dataTables.min.css"/>
<link type="text/css" rel="stylesheet" href="../lib/plugins/datatables/assets/datatables/extensions/FixedHeader/css/fixedHeader.dataTables.min.css"/>
<link type="text/css" rel="stylesheet" href="../lib/plugins/datatables/assets/datatables/extensions/FixedColumns/css/fixedColumns.dataTables.min.css"/>
<link type="text/css" rel="stylesheet" href="../lib/plugins/datatables/assets/datatables/extensions/Buttons/css/buttons.dataTables.min.css"/>
<link type="text/css" rel="stylesheet" href="../lib/plugins/datatables/assets/datatables/extensions/Responsive/css/responsive.dataTables.min.css"/>
<link type="text/css" rel="stylesheet" href="../lib/plugins/icons/assets/font-awesome/css/font-awesome.min.css"/>
<link type="text/css" rel="stylesheet" href="../lib/plugins/icons/assets/typicons/typicons.min.css"/>
<link type="text/css" rel="stylesheet" href="../lib/plugins/icons/assets/rpg-awesome/css/rpg-awesome.min.css"/>
<link type="text/css" rel="stylesheet" href="../lib/plugins/icons/assets/font-linux/font-linux.css"/>
<link type="text/css" rel="stylesheet" href="../lib/plugins/icons/assets/material-icons/material-icons.css"/>
<!--[if gte IE 9]><!-->
<script type="text/javascript">/*<![CDATA[*/var NS='درس';var JSINFO = {"plugin_folded":{"hide":"\u0645\u062e\u0641\u06cc\u200c\u0633\u0627\u0632\u06cc","reveal":"\u0622\u0634\u06a9\u0627\u0631\u0633\u0627\u0632\u06cc"},"plugin":{"datatables":{"config":[],"enableForAllTables":0}},"isadmin":0,"isauth":0,"move_renameokay":false,"id":"\u062f\u0631\u0633:\u06f4\u06f0\u06f8\u06f1\u06f6","namespace":"\u062f\u0631\u0633","ACT":"show","useHeadingNavigation":1,"useHeadingContent":1};
/*!]]>*/</script>
<script type="text/javascript" charset="utf-8" src="../lib/exe/jquery1d4f.php?tseed=23f888679b4f1dc26eef34902aca964f"></script>
<script type="text/javascript" charset="utf-8" src="../lib/exe/jsaa19.php?t=docs&amp;tseed=6edb3bd901a41874a3c4990e4362952b"></script>
<script type="text/x-mathjax-config">/*<![CDATA[*/MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ["$","$"], ["\\(","\\)"] ],
        displayMath: [ ["$$","$$"], ["\\[","\\]"] ],
        processEscapes: true
    }
});
/*!]]>*/</script>
<script type="text/javascript" charset="utf-8" src="../../cdn.icpc.ir/mathjax/MathJax5423.js?config=TeX-AMS_CHTML.js"></script>
<script type="text/javascript" src="../lib/plugins/datatables/assets/datatables/media/js/jquery.dataTables.min.js"></script>
<script type="text/javascript" src="../lib/plugins/datatables/assets/datatables/extensions/FixedHeader/js/dataTables.fixedHeader.min.js"></script>
<script type="text/javascript" src="../lib/plugins/datatables/assets/datatables/extensions/FixedColumns/js/dataTables.fixedColumns.min.js"></script>
<script type="text/javascript" src="../lib/plugins/datatables/assets/datatables/extensions/Buttons/js/dataTables.buttons.min.js"></script>
<script type="text/javascript" src="../lib/plugins/datatables/assets/datatables/extensions/Buttons/js/buttons.html5.min.js"></script>
<script type="text/javascript" src="../lib/plugins/datatables/assets/datatables/extensions/Buttons/js/buttons.print.min.js"></script>
<script type="text/javascript" src="../lib/plugins/datatables/assets/datatables/extensions/Responsive/js/dataTables.responsive.min.js"></script>
<!--<![endif]-->
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <link rel="shortcut icon" href="../_media/wiki/favicon.ico_%3b" />
<link rel="apple-touch-icon" href="../lib/tpl/docs/images/apple-touch-icon.png" />
    </head>

<body class="page-۴۰۸۱۶ ns-درس">
    <div id="dokuwiki__site"><div id="dokuwiki__top" class="site dokuwiki mode_show tpl_docs    showSidebar hasSidebar">

        
<!-- ********** HEADER ********** -->
<div id="dokuwiki__header"><div class="pad group">

    
    <div class="headings group">
        <ul class="a11y skip">
            <li><a href="#dokuwiki__content">پرش به محتوا</a></li>
        </ul>

        <h1><a href="../%d9%81%d9%87%d8%b1%d8%b3%d8%aa.html"  accesskey="h" title=" دانشکده علوم ریاضی "><img src="../_media/wiki/logo.png_%3b" width="417" height="417" alt="" /> <span> دانشکده علوم ریاضی </span></a></h1>
                    <p class="claim">دانشگاه صنعتی شریف</p>
            </div>

    <div class="tools group">
        <!-- USER TOOLS -->
                    <div id="dokuwiki__usertools">
                <h3 class="a11y">ابزار کاربر</h3>
                <ul>
                    <li class="action login"><a href="%db%b4%db%b0%db%b8%db%b1%db%b651ef.html?do=login&amp;sectok=" title="ورود به سیستم" rel="nofollow"><span>ورود به سیستم</span><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M10 17.25V14H3v-4h7V6.75L15.25 12 10 17.25M8 2h9a2 2 0 0 1 2 2v16a2 2 0 0 1-2 2H8a2 2 0 0 1-2-2v-4h2v4h9V4H8v4H6V4a2 2 0 0 1 2-2z"/></svg></a></li>                </ul>
            </div>
        
        <!-- SITE TOOLS -->
        <div id="dokuwiki__sitetools">
            <h3 class="a11y">ابزار سایت</h3>
            <form action="https://docs.ce.sharif.edu/فهرست" method="get" role="search" class="search doku_form" id="dw__search" accept-charset="utf-8"><input type="hidden" name="do" value="search" /><input type="hidden" name="id" value="درس:۴۰۸۱۶" /><div class="no"><input name="q" type="text" class="edit" title="[F]" accesskey="f" placeholder="جستجو" autocomplete="on" id="qsearch__in" value="" /><button value="1" type="submit" title="جستجو">جستجو</button><div id="qsearch__out" class="ajax_qsearch JSpopup"></div></div></form>            <div class="mobileTools">
                            </div>
            <ul>
                            </ul>
        </div>

    </div>

    <!-- BREADCRUMBS -->
            <div class="breadcrumbs">
                            <div class="youarehere"><span class="bchead">محل شما: </span><span class="home"><bdi><a href="../%d9%81%d9%87%d8%b1%d8%b3%d8%aa.html" class="wikilink1" title="فهرست">فهرست</a></bdi></span> » <bdi><a href="%d9%81%d9%87%d8%b1%d8%b3%d8%aa.html" class="wikilink1" title="درس:فهرست">سرفصل دروس</a></bdi> » <bdi><span class="curid"><a href="%db%b4%db%b0%db%b8%db%b1%db%b6.html" class="wikilink1" title="درس:۴۰۸۱۶">امنیت و حریم خصوصی در یادگیری ماشین</a></span></bdi></div>
                                </div>
    


    <hr class="a11y" />
</div></div><!-- /header -->

        <div class="wrapper group">

                            <!-- ********** ASIDE ********** -->
                <div id="dokuwiki__aside"><div class="pad aside include group">
                    <h3 class="toggle">نوار کناری</h3>
                    <div class="content"><div class="group">
                                                                        
<p>
<strong>فهرست مطالب</strong>
</p>

<div><div id="nojs_indexmenu_61511523863da20c00b7ba" data-jsajax="&sort=t&msort=indexmenu_n&nsort=1&nopg=1" class="indexmenu_nojs">

<ul class="idx">
<li class="closed"><div class="li"><a href="../%d8%a7%d8%b7%d9%84%d8%a7%d8%b9%db%8c%d9%87/%d9%81%d9%87%d8%b1%d8%b3%d8%aa.html" class="indexmenu_idx_head">اطلاعیه‌ها</a></div></li>
<li class="closed"><div class="li"><a href="../%d8%a8%d8%b1%d9%86%d8%a7%d9%85%d9%87/%d9%81%d9%87%d8%b1%d8%b3%d8%aa.html" class="indexmenu_idx_head">برنامه‌های درسی</a></div></li>
<li class="open"><div class="li"><a href="%d9%81%d9%87%d8%b1%d8%b3%d8%aa.html" class="indexmenu_idx_head">سرفصل دروس</a></div></li>
<li class="closed"><div class="li"><a href="../%d8%a2%db%8c%db%8c%d9%86_%d9%86%d8%a7%d9%85%d9%87/%d9%81%d9%87%d8%b1%d8%b3%d8%aa.html" class="indexmenu_idx_head">آيین‌نامه‌ها</a></div></li>
<li class="closed"><div class="li"><a href="../%d9%81%d8%b1%d9%85_%d9%87%d8%a7/%d9%81%d9%87%d8%b1%d8%b3%d8%aa.html" class="indexmenu_idx_head">فرم‌ها</a></div></li>
<li class="closed"><div class="li"><a href="../%d8%af%d8%b1%d8%a8%d8%a7%d8%b1%d9%87/%d9%81%d9%87%d8%b1%d8%b3%d8%aa.html" class="indexmenu_idx_head">درباره‌ی دانشکده</a></div></li>
</ul>
</div></div>

<p>
<br/>

<strong>گروه‌های آموزشی</strong>
</p>
<ul>
<li class="level1"><div class="li"> <a href="../../software.ce.sharif.edu/index.html" class="urlextern" title="http://software.ce.sharif.edu" rel="nofollow"> نرم‌افزار</a></div>
</li>
<li class="level1"><div class="li"> <a href="../../hardware.ce.sharif.edu/index.html" class="urlextern" title="http://hardware.ce.sharif.edu" rel="nofollow"> معماری کامپیوتر</a></div>
</li>
<li class="level1"><div class="li"> <a href="../../ai.ce.sharif.edu/index.html" class="urlextern" title="http://ai.ce.sharif.edu" rel="nofollow"> هوش مصنوعی</a></div>
</li>
<li class="level1"><div class="li"> <a href="../../it.ce.sharif.edu/index.html" class="urlextern" title="http://it.ce.sharif.edu" rel="nofollow"> فناوری اطلاعات</a></div>
</li>
</ul>
                                            </div></div>
                </div></div><!-- /aside -->
            
            <!-- ********** CONTENT ********** -->
            <div id="dokuwiki__content"><div class="pad group">
                
                <div class="pageId"><span>درس:۴۰۸۱۶</span></div>

                <div class="page group">
                                                            <!-- wikipage start -->
                    <div class="datatemplateentry درس">
<h1 class="sectionedit1" id="امنیت_و_حریم_خصوصی_در_یادگیری_ماشین">امنیت و حریم خصوصی در یادگیری ماشین</h1>
<div class="level1">

<p>
<strong>Security and Privacy of Machine Learning</strong>
</p>
<div class="table sectionedit2"><table class="inline" style="min-width: 0px; width: 100%;">
<col style="width: 50%" />
	<tr class="row0">
		<td class="col0"> <strong>شماره درس</strong>: ۴۰۸۱۶ </td><td class="col1"> <strong>تعداد واحد</strong>: ۳ </td>
	</tr>
	<tr class="row1">
		<td class="col0"> <strong>مقطع</strong>: کارشناسی ارشد </td><td class="col1"> <strong>نوع درس</strong>: نظری </td>
	</tr>
	<tr class="row2">
		<td class="col0"> <strong>پیش‌نیاز</strong>: آمار و احتمال مهندسی </td><td class="col1"> <strong>هم‌نیاز</strong>: – </td>
	</tr>
</table></div>

</div>
</div>
<h2 class="sectionedit1" id="اهداف_درس">اهداف درس</h2>
<div class="level2">

<p>
هدف از این درس آشنایی دانشجویان با امنیت و حریم خصوصی در یادگیری ماشین و نحوه افزایش مقاومت الگوریتم‌های یادگیری ماشین در برابر مهاجمان است. با افزایش حجم داده ها و پیشرفت الگوریتم‌های یادگیری ماشین، استفاده از یادگیری ماشین در کاربردهای مختلفی مانند پردازش تصویر، پردازش صدا، پردازش متن، سامانه‌های تصمیم‌گیر، و سامانه‌های امنیتی رشد زیادی داشته است. افزایش استفاده از یادگیری ماشین در کاربردهای گوناگون باعث شده است تا اهمیت امنیت و حریم خصوصی در الگوریتم های یادگیری ماشین افزایش یابد. در این درس دانشجویان با مهمترین آسیب‌پذیری‌های امنیتی یادگیری ماشین مانند نمونه خصمانه و مسمومیت داده‌های آموزش در کاربردهای گوناگون مانند پردازش تصویر و صدا آشنا می‌شوند و راهکار‌های مقاوم‌سازی مدل یادگیری ماشین در برابر این حملات نیز معرفی می‌شوند. همچنین مفهوم حریم خصوصی در یادگیری ماشین معرفی می شود و ضعف‌ الگوریتم‌های یادگیری ماشین در نشت اطلاعات مهم و نحوه حفظ حریم خصوصی در این الگوریتم‌ها بررسی می‌شود. به دلیل عملکرد درخشان یادگیری ژرف تمرکز این درس بر روی این الگوریتم‌ها است.
</p>

</div>

<h2 class="sectionedit2" id="ریز_مواد">ریز مواد</h2>
<div class="level2">
<ul>
<li class="level1 node"><div class="li"> <strong>مبانی یادگیری ماشین</strong></div>
<ul>
<li class="level2"><div class="li"> تعریف انواع الگوریتم‌های یادگیری ماشین (با نظارت، بدون نظارت، و نیمه‌نظارتی)</div>
</li>
<li class="level2"><div class="li"> معرفی معیارهای ارزیابی الگوریتم‌های یادگیری ماشین</div>
</li>
</ul>
</li>
<li class="level1 node"><div class="li"> <strong>یادگیری ژرف</strong></div>
<ul>
<li class="level2"><div class="li"> معرفی دسته‌بندهای خطی</div>
</li>
<li class="level2"><div class="li"> مبانی شبکه‌های عصبی </div>
</li>
<li class="level2"><div class="li"> الگوریتم گرادیان کاهشی</div>
</li>
<li class="level2"><div class="li"> تابع هزینه و الگوریتم انتشار به عقب</div>
</li>
<li class="level2"><div class="li"> معرفی شبکه‌های عصبی پیچشی و انواع ان</div>
</li>
</ul>
</li>
<li class="level1 node"><div class="li"> <strong>حملات نمونه خصمانه و روش‌های افزایش مقاومت مدل در برابر آن‌ها</strong></div>
<ul>
<li class="level2"><div class="li"> معرفی نمونه‌های خصمانه</div>
</li>
<li class="level2"><div class="li"> قابلیت انتقال نمونه‌های خصمانه</div>
</li>
<li class="level2"><div class="li"> نمونه‌های خصمانه در کاربردهای گوناگون</div>
</li>
<li class="level2"><div class="li"> نمونه‌های خصمانه در دنیای واقعی</div>
</li>
<li class="level2"><div class="li"> نمونه‌های خصمانه جعبه-سیاه</div>
</li>
<li class="level2"><div class="li"> آموزش خصمانه</div>
</li>
<li class="level2"><div class="li"> درستی‌یابی مدل</div>
</li>
<li class="level2"><div class="li"> تشخیص نمونه‌های خصمانه</div>
</li>
</ul>
</li>
<li class="level1 node"><div class="li"> <strong>حملات مسموم ‌سازی دادگان آموزش و روش‌‌های دفاعی در برابر آن‌ها</strong></div>
<ul>
<li class="level2"><div class="li"> حملات مسموم‌ سازی دادگان آموزش</div>
</li>
<li class="level2"><div class="li"> افزایش مقاومت مدل در مقابل حملات مسموم‌ سازی دادگان آموزش</div>
</li>
</ul>
</li>
<li class="level1"><div class="li"> <strong>حملات سرقت مدل و روش‌های دفاعی در برابر آن‌ها</strong></div>
</li>
<li class="level1 node"><div class="li"> <strong>حریم خصوصی در یادگیری ماشین</strong></div>
<ul>
<li class="level2"><div class="li"> معرفی مفهوم حریم خصوصی در یادگیری ماشین</div>
</li>
<li class="level2"><div class="li"> حمله استنتاج عضویت</div>
</li>
</ul>
</li>
<li class="level1 node"><div class="li"> <strong>یادگیری ماشین حافظ حریم خصوصی</strong></div>
<ul>
<li class="level2"><div class="li"> حریم‌خصوصی تفاضلی</div>
</li>
<li class="level2"><div class="li"> حریم‌خصوصی تفاضلی در یادگیری ماشین</div>
</li>
</ul>
</li>
</ul>

</div>

<h2 class="sectionedit3" id="ارزیابی">ارزیابی</h2>
<div class="level2">
<ul>
<li class="level1"><div class="li"> مرور مقالات: ۶ نمره</div>
</li>
<li class="level1"><div class="li"> تکالیف: ۶ نمره</div>
</li>
<li class="level1"><div class="li"> پروژه: ۲ نمره</div>
</li>
<li class="level1"><div class="li"> پایان‌ترم: ۶ نمره</div>
</li>
</ul>

</div>

<h2 class="sectionedit4" id="مراجع">مراجع</h2>
<div class="level2">
<div class="plugin_wrap" lang="en" xml:lang="en" dir="ltr"><ol>
<li class="level1"><div class="li">	C. M. Bishop and C. M., Pattern recognition and machine learning. Springer, 2006.</div>
</li>
<li class="level1"><div class="li">	I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning. The MIT Press, 2016.</div>
</li>
<li class="level1"><div class="li">	C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus “Intriguing properties of neural networks,” in Proceedings of the International Conference on Representation Learning (ICLR), 2014.</div>
</li>
<li class="level1"><div class="li">	I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and Harnessing Adversarial Examples,” in Proceedings of the International Conference on Representation Learning (ICLR), 2015.</div>
</li>
<li class="level1"><div class="li">	N. Carlini and D. Wagner, “Towards Evaluating the Robustness of Neural Networks,” in 2017 IEEE Symposium on Security and Privacy (SP), 2017, pp. 39–57.</div>
</li>
<li class="level1"><div class="li">	Y. Liu, X. Chen, C. Liu, and D. Song, “Delving into Transferable Adversarial Examples and Black-box Attacks,” in Proceedings of the International Conference on Representation Learning (ICLR), 2017.</div>
</li>
<li class="level1"><div class="li">	S.-M. Moosavi-Dezfooli, A. Fawzi, O. Fawzi, and P. Frossard, “Universal Adversarial Perturbations,” in EEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 1765–1773.</div>
</li>
<li class="level1"><div class="li">	N. Carlini and D. Wagner, “Audio Adversarial Examples: Targeted Attacks on Speech-to-Text,” in 2018 IEEE Security and Privacy Workshops (SPW), 2018, pp. 1–7.</div>
</li>
<li class="level1"><div class="li">	M. Osadchy, J. Hernandez-Castro, S. Gibson, O. Dunkelman, and D. Perez-Cabo, “No Bot Expects the DeepCAPTCHA! Introducing Immutable Adversarial Examples, With Applications to CAPTCHA Generation,” IEEE Trans. Inf. Forensics Secur., vol. 12, no. 11, pp. 2640–2653, Nov. 2017.</div>
</li>
<li class="level1"><div class="li">	K. Grosse, N. Papernot, P. Manoharan, M. Backes, and P. McDaniel, “Adversarial Examples for Malware Detection,” in uropean Symposium on Research in Computer Security, 2017, pp. 62–79.</div>
</li>
<li class="level1"><div class="li">	N. Carlini, P. Mishra, T. Vaidya, Y. Zhang, M. Sherr, C. Shields, D. Wagner, and W. Zhou, “Hidden voice commands,” in 25th USENIX Security Symposium, 2016, pp. 513–530.</div>
</li>
<li class="level1"><div class="li">	A. Kurakin, I. J. Goodfellow, and S. Bengio, “Adversarial examples in the physical world,” in Proceedings of the International Conference on Representation Learning (ICLR), 2017.</div>
</li>
<li class="level1"><div class="li">	D. Song, K. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, F. Tramer, A. Prakash, and T. Kohno., “Physical Adversarial Examples for Object Detectors,” in 12th USENIX Workshop on Offensive Technologies (WOOT18), 2018.</div>
</li>
<li class="level1"><div class="li">	P. Chen, H. Zhang, Y. Sharma, J. Yi, and C. Hsieh. &quot;Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models.&quot; In Proceedings of the 10th ACM workshop on artificial intelligence and security, 2017, pp. 15-26. </div>
</li>
<li class="level1"><div class="li">	A. Ilyas, L. Engstrom, A. Athalye, and J. Lin. &quot;Black-box adversarial attacks with limited queries and information.&quot; In International Conference on Machine Learning, 2018, pp. 2137-2146.</div>
</li>
<li class="level1"><div class="li">	B. Wang and N. Z. Gong, “Stealing Hyperparameters in Machine Learning,” in 2018 IEEE Symposium on Security and Privacy (SP), 2018, pp. 36–52.</div>
</li>
<li class="level1"><div class="li">	F. Tramèr, F. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart, “Stealing Machine Learning Models via Prediction APIs,” in 25th USENIX Security Symposium, 2016, pp. 601–618.</div>
</li>
<li class="level1"><div class="li">	A. Shafahi, W. Huang, M. Najibi, O. Suciu, C. Studer, T. Dumitras, and T. Goldstein, “Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks,” in Advances in Neural Information Processing Systems 31, 2018, pp. 6103–6113.</div>
</li>
<li class="level1"><div class="li">	B. Tran, J. Li, and A. Madry, “Spectral Signatures in Backdoor Attacks,” in Advances in Neural Information Processing Systems 31, 2018, pp. 8000–8010.</div>
</li>
<li class="level1"><div class="li">	A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, “Towards Deep Learning Models Resistant to Adversarial Attacks,” in Proceedings of the International Conference on Representation Learning (ICLR), 2018.</div>
</li>
<li class="level1"><div class="li">	F. Tramèr, A. Kurakin, N. Papernot, I. Goodfellow, D. Boneh, and P. McDaniel, “Ensemble Adversarial Training: Attacks and Defenses,” in Proceedings of the International Conference on Representation Learning (ICLR), 2017.</div>
</li>
<li class="level1"><div class="li">	N. Papernot, P. McDaniel, X. Wu, S. Jha, and A. Swami, “Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks,” in 2016 IEEE Symposium on Security and Privacy (SP), 2016, pp. 582–597.</div>
</li>
<li class="level1"><div class="li">	A. Sinha, H. Namkoong, and J. Duchi, “Certifying Some Distributional Robustness with Principled Adversarial Training,” in Proceedings of the International Conference on Representation Learning (ICLR), 2017.</div>
</li>
<li class="level1"><div class="li">	G. Katz, C. Barrett, D. L. Dill, K. Julian, and M. J. Kochenderfer, “Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks,” in International Conference on Computer Aided Verification, 2017, pp. 97–117.</div>
</li>
<li class="level1"><div class="li">	D. Meng and H. Chen, “MagNet: a Two-Pronged Defense against Adversarial Examples,” in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security - CCS ’17, 2017, pp. 135–147.</div>
</li>
<li class="level1"><div class="li">	N. Baracaldo, B. Chen, H. Ludwig, and J. A. Safavi, “Mitigating Poisoning Attacks on Machine Learning Models,” in Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security  - AISec ’17, 2017, pp. 103–110.</div>
</li>
<li class="level1"><div class="li">	J. Steinhardt, P. Koh, and P. Liang, “Certified Defenses for Data Poisoning Attacks,” in Advances in Neural Information Processing Systems 30, 2017, pp. 3517–3529.</div>
</li>
<li class="level1"><div class="li">	R. Shokri, M. Stronati, C. Song, and V. Shmatikov, “Membership Inference Attacks Against Machine Learning Models,” in 2017 IEEE Symposium on Security and Privacy (SP), 2017, pp. 3–18.</div>
</li>
<li class="level1"><div class="li">	C. Song, T. Ristenpart, and V. Shmatikov, “Machine Learning Models that Remember Too Much,” in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security  - CCS ’17, 2017, pp. 587–601.</div>
</li>
<li class="level1"><div class="li">	C. Dwork and A. Roth, “The Algorithmic Foundations of Differential Privacy,” Found. Trends. Theor. Comput. Sci., vol. 9, no. 3–4, pp. 211–407, 2013.</div>
</li>
<li class="level1"><div class="li">	R. Shokri and V. Shmatikov, “Privacy-Preserving Deep Learning,” in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS ’15, 2015, pp. 1310–1321.</div>
</li>
<li class="level1"><div class="li">	M. Abadi et al., “Deep Learning with Differential Privacy,” in Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security - CCS’16, 2016, pp. 308–318.</div>
</li>
<li class="level1"><div class="li">	P. Mohassel and Y. Zhang, “SecureML: A System for Scalable Privacy-Preserving Machine Learning,” in 2017 IEEE Symposium on Security and Privacy (SP), 2017, pp. 19–38.</div>
</li>
</ol>
</div>
</div>

                    <!-- wikipage stop -->
                                    </div>

                <div class="docInfo"><bdi>درس/۴۰۸۱۶.txt</bdi> · آخرین ویرایش: 2022/12/18 16:02 توسط <bdi>مرتضی امینی</bdi></div>

                            </div></div><!-- /content -->

            <hr class="a11y" />

            <!-- PAGE ACTIONS -->
                    </div><!-- /wrapper -->

        
<!-- ********** FOOTER ********** -->
<div id="dokuwiki__footer"><div class="pad">
    <p>کلیه‌ی حقوق این سایت متعلق  به دانشکده  علوم ریاضی است.</p>
    
    <div class="buttons">
            </div>
</div></div><!-- /footer -->

    </div></div><!-- /site -->

    <div class="no"><img src="../lib/exe/indexer8c50.gif?id=%D8%AF%D8%B1%D8%B3%3A%DB%B4%DB%B0%DB%B8%DB%B1%DB%B6&amp;1675877522" width="2" height="1" alt="" /></div>
    <div id="screen__mode" class="no"></div></body>

<!-- Mirrored from docs.ce.sharif.edu/درس/۴۰۸۱۶ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 08 Feb 2023 17:37:38 GMT -->
</html>
