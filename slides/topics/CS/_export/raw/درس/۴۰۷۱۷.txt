
---- اطلاعات درس ----

شماره: ۴۰۷۱۷
عنوان: یادگیری ماشین
عنوان انگلیسی: Machine Learning
مقطع: کارشناسی ارشد
گرایش: هوش مصنوعی
واحد: ۳
نوع: نظری
دسته: اصلی
پیش‌نیاز: آمار و احتمال مهندسی، جبر خطی
هم‌نیاز: --
متولی: گروه هوش مصنوعی
طراح:‌ دکتر بیگی
آخرین تصویب: --

قالب: قالب درس
----------------------------


===== اهداف درس =====

در این درس مفاهیم یادگیری ماشین مطرح شده و آشنایی با شاخه‌های مختلف این زمینه صورت گرفته و جنبه‌های مهم عملی و نظری آن معرفی خواهد شد. در شاخه‌های مختلف تکنیک‌ها و الگوریتم‌های مهم بحث می‌شود. در حوزه‌ی یادگیری با ناظر، مسائل رگرسیون و دسته‌بندی مورد بررسی قرار خواهند گرفت و روش‌های حل این مسائل و ارزیابی مدل‌ها معرفی خواهد شد. برای مساله دسته‌بندی انواع دیدگاه‌ها و الگوریتم‌های مربوطه مطرح می‌شود. در بخش یادگیری بدون ناظر در مورد تخمین چگالی، کاهش ابعاد بدون‌ناظر و خوشه‌بندی صحبت خواهد شد. در نهایت آشنایی مختصری با شاخه‌ی یادگیری تقویتی صورت خواهد گرفت.

===== ریز مواد =====

  - ** مقدمه‌ای بر یادگیری ماشین و مرور مباحث احتمال و جبرخطی ** (۱ جلسه)
  - ** روش‌های تخمین ML و MAP ** (‏۱ جلسه)
  - ** رگرسیون ** (۳ جلسه)
    * رگرسیون خطی و غیرخطی
    * بیش‌برازش (overfitting)
    * تجزیه‌ی خطا به بایاس (bias)، واریانس (variance) و نویز
    * منظم‌سازی (regularization)
    * رگرسیون آماری (statistical): ارتباط توابع هدف مبتنی بر SSE با تخمین‌های احتمالی ML و MAP برای مساله‌ی رگرسیون 
  - ** ارزیابی (evaluation) و تنظیم کردن مدل‌ها ** (۱ تا ۲ جلسه)
    * اعتبارسنجی (validation)
    * اعتبارسنجی متقابل (Cross-validation)
    * انتخاب مدل (model selection)
    * انتخاب ویژگی (feature selection)
  - ** دسته‌بندی (classification) **
    * دسته‌بندهای احتمالی (probabilistic classifiers) (سه جلسه) 
    * تئوری تصمیم (decision theory) و دسته‌بند بهینه بیز (Bayes optimal classifier) 
    * دسته‌بندی احتمالی جداساز (discriminative) و مولد (generative)
    * Logistic regression دو دسته‌ای و چند دسته‌ای (multi-class) و  بیز ساده (Naïve Bayes)
  - ** دسته‌بندی با استفاده از توابع جداسازی (discriminant functions) ** (شش جلسه)
    * پرسپترون (Perceptron)
    * جداساز خطی فیشر (Fisher)
    * ماشین بردار پشتیبان (SVM) و هسته (kernel)
    * شبکه‌های عصبی (neural networks)
  - ** درخت تصمیم (Decision Tree) ** (یک جلسه)
    * آنتروپی و بهره اطلاعاتی (Information Gain)
    * الگوریتم ID۳
    * توقف رشد و هرس درخت تصمیم
  - ** روش‌های یادگیری مبتنی بر نمونه (instance-based) ** (دو جلسه)
    * تخمین چگالی غیر پارامتری (Non-parametric density estimation) 
    * دسته‌بند k-نزدیکترین همسایه (k-Nearest Neighbors)
    * رگرسیون خطی وزن‌دار محلی (Locally Weighted Linear Regression)
  - ** تئوری یادگیری محاسباتی ** (۲ جلسه)
    * PAC-learning
    * VC dimension
    * کمینه‌سازی ریسک ساختاری (structural risk minimization)
  - ** یادگیری جمعی (ensemble learning) ** (دو جلسه)
    * Boosting و Bagging 
    * AdaBoost
  - ** کاهش ابعاد (dimensionality reduction) بدون ناظر ** (۲ جلسه)
    * تحلیل مولفه اصلی (PCA)
    * تحلیل مولفه مستقل (ICA)
  - ** خوشه‌بندی (clustering) ** (سه جلسه)
    * روش‌های افرازی (EM+GMM، k-means: (partitional 
    * روش‌های سلسله مراتبی (hierarchical)
  - ** یادگیری تقویتی (reinforcement learning) ** (دو جلسه)
    *  فرایند تصمیم مارکوف (MDP)
    * روش‌های یادگیری مبتنی بر مدل (model-based) 
    * روش تکرار مقدار (value iteration) و تکرار سیاست (policy iteration)
    * روش‌های یادگیری بی مدل (model-free)
    * الگوریتم‌های SARSA، Q-learning، تفاضل زمانی (Temporal Difference)
  - ** مباحث پیشرفته در یادگیری ماشین **
 

===== ارزیابی =====

  * تمرین: ۲۰٪
  * میان‌ترم: ۲۵٪
  * پایان‌ترم: ۳۵٪
  * امتحان‌های کوتاه: ۱۰٪ 
  * پروژه: ۱۰٪

===== مراجع =====

<div :en>
  - C. Bishop. //Pattern Recognition and Machine Learning//. Springer, 2006.
  - T. Mitchell. //Machine Learning//. MIT Press, 1998.
  - K. Murphy. //Machine Learning: A Probabilistic Perspective//. MIT Press, 2012.
  - T. Hastie, R. Tibshirani, and J. Friedman. //The elements of statistical learning//. 2nd Edition, 2008.
</div>