<!doctype html>
<html lang="en">

<head>
<meta charset="utf-8">

<title>Deep Learning Course, HSU</title>

<meta name="description" content="Deep Learning Course, Hakim Sabzevari University, Department of Computer Science">
<meta name="author" content="Mahmood Amintoosi">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

<meta name="viewport" content="width=device-width, initial-scale=1.0">

<link rel="stylesheet" href="../../css/reset.css">
<link rel="stylesheet" href="../../css/reveal.css">
<link rel="stylesheet" href="../../css/theme/serif.css" id="theme">

<!-- Theme used for syntax highlighting of code -->
<link rel="stylesheet" href="../../lib/css/monokai.css">

<!-- Printing and PDF exports -->
<script>
var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? '../../css/print/pdf.css' : '../../css/print/paper.css';
document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>

<!--[if lt IE 9]>
<script src="../../lib/js/html5shiv.js"></script>
<![endif]-->
</head>

<body>

<div class="reveal">

<!-- Any section element inside of this container is displayed as a slide -->
<div class="slides">
<!--
<section>
	<h1>Reveal.js</h1>
	<h3>The HTML Presentation Framework</h3>
	<p>
		<small>Created by <a href="http://hakim.se">Hakim El Hattab</a> and <a href="https://github.com/hakimel/reveal.js/graphs/contributors">contributors</a></small>
	</p>
</section>
<section id="themes">
	<h2>Themes</h2>
	<p>
		reveal.js comes with a few themes built in: <br>
		<!-- Hacks to swap themes after the page has loaded. Not flexible and only intended for the reveal.js demo deck. 
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/black.css'); return false;">Black (default)</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/white.css'); return false;">White</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/league.css'); return false;">League</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/sky.css'); return false;">Sky</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/beige.css'); return false;">Beige</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/simple.css'); return false;">Simple</a> <br>
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/serif.css'); return false;">Serif</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/blood.css'); return false;">Blood</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/night.css'); return false;">Night</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/moon.css'); return false;">Moon</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/solarized.css'); return false;">Solarized</a>
	</p>
</section> -->
<section>
 <h1>یادگیری عمیق</h1>
 <h3>دانشگاه حکیم سبزواری</h3>
 <h4>محمود امین‌طوسی</h4>
 <h3>Deep Learning</h3>
 <h4>Mahmood Amintoosi</h4>
 <p>
  <small><a href="http://https://mamintoosi.github.io/">m.amintoosi</a> @ <a href="http://hsu.ac.ir/">hsu.ac.ir</a></small>
 </p>
 <p>
  <small>پاییز ۹۸</small>
 </p>
</section>

<section>
 <h2>Source book</h2>
	Deep Learning with Python, 
	<br>
	by: FRANÇOIS CHOLLET
	<br>
	<img height="400" src="./images/DeepLearningWithPython-book-cover.jpg" alt="Deep Learning with Python" xstyle="border:none;box-shadow:none">
 
</section>

<section>
  <section data-background="#dddddd">
   <h2>Chapter 1</h2>
   <h3>What is deep learning?</h3>
	<img height="400" src="./images/AI-ML-DL-Fig1.1.png" alt="Deep Learning" xstyle="border:none;box-shadow:none">
  </section>

  <section>
   <h2>Domains and Applications</h2>
   <p>Google Street-View (and ReCaptchas)</p>
   <img width="598" height="400" src="./images/house-numbers_598x400.png" alt="House Numbers" xstyle="border:none;box-shadow:none">
   <p><i>
     <a href="http://arxiv.org/abs/1312.6082" target="_blank">Better</a> 
      than
     <a href="http://www.geek.com/news/googles-neutral-networks-are-now-better-than-humans-at-reading-addresses-1581653/" target="_blank">Human </a>
   </i></p>
  </section>

  <section class="future" hidden="" style="top: -20px; display: none;">
   <h2>Image Classification</h2>
   <img width="574" height="469" src="./images/ImageNet-Results_574x469.png" alt="ImageNet Results" style="border:none;box-shadow:none">
   <p><i>(now better than human level)</i></p>
  </section>

  <section class="future" hidden="" style="top: -20px; display: none;">
   <h2>Captioning Images</h2>
   <img width="667" height="419" src="./images/image-labelling-results_667x419.png" alt="Labelling Results" style="border:none;box-shadow:none">
   <p><i>Some good, some not-so-good</i></p>
  </section>

  <section class="future" hidden="" style="top: -350px; display: block;">
   <h2>Speech Recognition</h2>
   <p>Android feature since <a href="http://www.phonearena.com/news/The-secret-of-Googles-amazing-voice-recognition-revealed-it-works-like-a-brain_id39938" target="_blank">Jellybean (v4.3, 2012)</a> using Cloud</p>
   <p>Trained in ~5 days on 800 machine cluster</p>
   <img width="444" height="360" src="./images/speech_444x360.png" alt="Speech Recognition" xstyle="border:none;box-shadow:none">
   <p>Embedded in phone since Android <a href="http://googleresearch.blogspot.sg/2015/08/the-neural-networks-behind-google-voice.html" target="_blank">Lollipop (v5.0, 2014)</a></p>
  </section>

  <section class="future" hidden="" style="top: -268px; display: block;">
   <h2>Translation</h2>
   <p>Google's <a href="http://googleresearch.blogspot.sg/2015/07/how-google-translate-squeezes-deep.html" target="_blank">Deep Models</a> are on the phone</p>
   <img width="640" height="160" src="./images/google-translate_640x160.png" alt="Google Translate" xstyle="border:none;box-shadow:none">
   <p><i>"Use your camera to translate text instantly in 26 languages"</i></p>
   <p><i>Translations for typed text in 90 languages</i></p>
  </section>

<!--  
  <section>
   <h2>Reinforcement Learning</h2>
   <p>Google's DeepMind purchase</p>
   <p>Learn to play games from the pixels alone</p>
   <img width="562" height="466" src="img/deep-mind_562x466.jpg" alt="DeepMind Atari" style="border:none;box-shadow:none">
   <p><i>Better than humans 2 hours after switching on</i></p>
  </section>
!-->

  <section class="future" hidden="" style="top: -20px; display: none;">
   <h2>Reinforcement Learning</h2>
   <p>Google DeepMind's AlphaGo</p>
   <p>Learn to play Go from (mostly) self-play</p>
   <img width="902" height="337" src="./images/AlphaGo-match5_902x337.png" alt="DeepMind AlphaGo Match 5" style="border:none;box-shadow:none">
  </section>

</section>


<section data-background="./images/GeoffHinton.jpeg">
	<section class="" style="top: -277px; display: block;">
		<h3>Machine learning vs. Classical programming</h3>
		<h4>Machine learning: a new programming paradigm</h4>
		<img height="400" src="./images/Prog-ML-Fig1.2.png" alt="Machine learning: a new programming paradigm" xstyle="border:none;box-shadow:none">
	</section>
  <section style="top: -20px; display: none;">
   <h2>Machine learning</h2>
   <ul class="fix-spacing">
    <li>Input data points</li>
    <li>Examples of the expected output</li>
	<li>A way to measure whether the algorithm is doing a good job</li>
   </ul>
   <p>
   A machine-learning model transforms its input data into meaningful outputs, a process that is “learned” from exposure to known examples of inputs and outputs. Therefore, the central problem in machine learning and deep learning is to meaningfully transform data.
   </p>
  </section>
  
  <section >
   <h2>The “deep” in deep learning</h2>
   <ul class="fix-spacing">
    <li>The deep in deep learning isn’t a reference to any kind of deeper understanding achieved by the approach; . </li>
    <li>it stands for this idea of successive layers of representations</li>
    <li> How many layers contribute to a model of the data is called the depth of the model.</li>
   </ul>
  </img></section>
    
</section>

<section data-transition="slide" data-background="#4d7e65" data-background-transition="zoom">
	<section >
		<h2>Deep Learning Layers</h2>
		   <img height="444" src="images/A deep neural network for digit classification-fig 1.5.png" alt="DL digit" style="border:none">
	</section>
	<section >
		<h2>Deep Learning Layers</h2>
		   <img height="444" src="images/Deep representations learned by a digit-classification model-fig 1.6.png" alt="DL digit" style="border:none;box-shadow:none">
	</section>
	<section >
		<h2>Neural Networks</h2>
		   <img height="444" src="images/Figure 1.7 A neural network is parameterized by its weights.png" alt="DL digit" style="border:none;box-shadow:none">
	</section>
	<section >
		<h2>Loss Function</h2>
		   <img height="444" src="images/Figure 1.8 A loss function measures the quality of the networks output.png" alt="Loss Function" style="border:none;box-shadow:none">
	</section>
	<section >
		<h2>Optimizer</h2>
		   <img height="444" src="images/Figure 1.9 The loss score is used as a feedback signal to adjust the weights.png" alt="Optimizer" style="border:none;box-shadow:none">
	</section>

</section>

<section>
  <section data-transition="convex">
   <h2>Deep Learning breakthroughs</h2>
   <small>
   <ul class="fix-spacing">
    <li>Near-human-level image classification</li>
    <li>Near-human-level speech recognition</li>
    <li>Near-human-level handwriting transcription</li>
	<li>Improved machine translation  </li>
	<li>Improved text-to-speech conversion  </li>
	<li>Digital assistants such as Google Now and Amazon Alexa  </li>
	<li>Near-human-level autonomous driving  </li>
	<li>Ability to answer natural-language questions  </li>
	<li>Ability to answer natural-language questions  </li>
   </ul>
   </small>
  </section>
  <section data-transition="convex" >
   <h2>Deep Learning</h2>
   <ul class="fix-spacing">
    <li>Neural Networks</li>
    <li>Multiple layers</li>
    <li>Fed with lots of Data</li>
   </ul>
  </section>
  <section data-transition="convex">
   <h2>History</h2>
   <ul class="fix-spacing">
    <li>1980+ : Lots of enthusiasm for NNs</li>
    <li>1995+ : Disillusionment = A.I. Winter (v2+)</li>
    <li>2005+ : Stepwise improvement : Depth</li>
    <li>2010+ : GPU revolution : Data</li>
   </ul>
  </section>
  <section data-transition="convex">
   <h2>Who is involved</h2>
   <ul class="fix-spacing">
    <li>Google - Hinton (Toronto)</li>
    <li>Facebook - LeCun (NYC)</li>
    <li>Universities, eg: Montreal (Bengio)</li>
    <li>Baidu - Ng (Stanford)</li>
    <li>... Apple (acquisitions), etc</li>
   </ul>
   <br>
   <img src="images/BHL2.jpeg" width="300">
  </section>
  <section data-transition="convex">
   <h3>Who is involved</h3>
	<table>
		<tbody>
			<tr>
				<td>Google </td>
				<td>Hinton (Toronto)</td>
				<td><img src="images/GeoffHinton.jpeg" width="90"></td>
			</tr>
			<tr>
				<td>Facebook</td>
				<td>LeCun (NYC)</td>
				<td><img src="images/YannLeCun.jpeg" width="90"></td>
			</tr>
			<tr>
				<td>Universities</td>
				<td>Bengio (Montreal)</td>
				<td><img src="images/YoshuaBengio.jpeg" width="90"></td>
			</tr>
			<tr>
				<td>Baidu</td>
				<td>Ng (Stanford)</td>
				<td><img src="images/AndrewNg.jpeg" width="90"></td>
			</tr>
		</tbody>
	</table>
  </section>
  <section>
   <h2>Andrew Ng:</h2>
   <blockquote cite="https://www.gsb.stanford.edu/insights/andrew-ng-why-ai-new-electricity">
						&ldquo;AI is the new electricity.&rdquo;
	</blockquote>
  </section>
</section>


<section class="stack present" style="top: 0px; display: block;" data-previous-indexv="1">
  <section class="past" style="top: -180.5px; display: block;" hidden="">
   <h2>Basic Approach</h2>
   <ul class="fix-spacing">
    <li>Same as original Neural Networks since 1980s</li>
    <li>Simple mathematical units ...</li>
    <li style="list-style-type:none"> ... combine to compute a complex function</li>
   </ul>
  </section>

  <section class="past" style="top: -320px; display: block;" hidden="">
   <h2>Single "Neuron"</h2>
   <img width="602" height="381" src="./images/one-neuron_602x381.png" alt="One Neuron" style="border:none;box-shadow:none">
   <p>Change weights to change output function</p>
  </section>

  <section class="present" style="top: -313px; display: block;">
   <h2>Multi-Layer</h2>
   <p>Layers of neurons combine and <br>can form more complex functions</p>
   <img width="356" height="324" src="./images/multi-layer_356x324.png" alt="Multi-Layer" style="border:none;box-shadow:none">
  </section>

<!--
  <section>
   <h2>Supervised Learning</h2>
   <ul class="fix-spacing">
    <li><strong>while</strong> not done :</li>
    <li style="list-style-type:none">
      <ul>
        <li>Pick a training case (<code>x</code> &rarr; <code>target_y</code>)</li>
        <li>Evaluate <code>output_y</code> from the <code>x</code></li>
        <li>Modify the weights so that <code>output_y</code> is closer to <code>target_y</code> for that <code>x</code></li>
      </ul>
    </li>
   </ul>
  </section>

  <section>
   <h2>Gradient Descent</h2>
   <p>Follow the gradient of the error <br />w.r.t the connection weights</p>
   <img width="364" height="306" src="img/gradient-descent_364x306.png" alt="Gradient-Descent" style="border:none;box-shadow:none">
  </section>
!-->

</section>

<section data-background-transition="zoom">
  <section style="top: -350px; display: block;">
   <h2>Workshop : Neurons and Features</h2>
   <ul>
    <li style="list-style-type:none">
     <ul>
      <li>Go to the Javascript Example : TensorFlow</li>
     </ul>
    </li>
   </ul>
   <img width="507" height="387" src="./images/Tensorflow-PlayGound-local_507x387.png" alt="TensorFlow Playground" style="border:none;box-shadow:none">
   <p><small>(or search online for TensorFlow Playground)</small></p>
  </section>
  
  <section data-background-transition="concave">
   <h2>TensorFlow Playground</h2>
   <img width="778" height="443" src="./images/Tensorflow-PlayGound-layout_778x443.png" alt="TensorFlow Layout" style="border:none;box-shadow:none">
  </section>

  <section class="future" style="top: -213px; display: block;">
   <h2>Things to Understand</h2>
   <ul>
    <li>Hands-on : </li>
    <li style="list-style-type:none">
     <ul>
      <li>Goal : learning to predict regions</li>
      <li>Input features</li>
      <li>What a single neuron can learn</li>
      <li>The blame game</li>
      <li>How deep networks 'create' features</li>
     </ul>
    </li>
   </ul>
  </section>
  
<!--
  <section>
   <h2>Things to Do</h2>
   <ul>
    <li>Investigate : </li>
    <li style="list-style-type:none">
     <ul>
      <li>Minimal set of features</li>
      <li>Minimal # of layers</li>
      <li>Minimal widths</li>
      <li>Effect of going less-minimal...</li>
     </ul>
    </li>
   </ul>
  </section>
!-->
</section>


<!--
<section>
  <section>
   <h2>Workshop : SGD</h2>
    <ul>
     <li style="list-style-type:none">
      <ul>
        <li>Go to : <code>http://ConvNetJS.com/</code></li>
        <li>Look for : "Image 'painting'"</li>
      </ul>
    </li>
   </ul>
   <ximg width="473" height="665" src="img/ConvNetJS-Painting_473x665.png" alt="ConvNetJS Image Painting" style="border:none;box-shadow:none">
   <img width="844" height="418" src="img/ConvNetJS-Painting_844x418.png" alt="ConvNetJS Image Painting" style="border:none;box-shadow:none">
  </section>
  
  <section>
   <h2>Simple Network</h2>
   <img width="574" height="435" src="img/ConvNetJS-Painting-5_574x435.png" alt="ConvNetJS Painting : 5" style="border:none;box-shadow:none">
  </section>
  <section>
   <h2>Wider Network</h2>
   <img width="573" height="443" src="img/ConvNetJS-Painting-20_573x443.png" alt="ConvNetJS Painting : 20" style="border:none;box-shadow:none">
  </section>
  <section>
   <h2>Two-Ply Network</h2>
   <img width="571" height="427" src="img/ConvNetJS-Painting-10-10_571x427.png" alt="ConvNetJS Painting : 10+10" style="border:none;box-shadow:none">
  </section>
  <section>
   <h2>Deep Network and Time</h2>
   <img width="575" height="435" src="img/ConvNetJS-Painting-7x20_575x435.png" alt="ConvNetJS Painting : 10x7" style="border:none;box-shadow:none">
  </section>
</section>
!-->

<!--
<section>
  <section>
   <h2>"Hello World" &rarr; MNIST</h2>
   <ul class="fix-spacing">
    <li>Nice dataset from the late 1980s</li>
    <li>Training set of 50,000 28x28 images</li>
    <li>Now end-of-life as a useful benchmark</li>
   </ul>
   <br />
   <img width="255" height="204" src="img/mnist_100_digits_255x204.png" alt="MNIST digits" style="border:none;box-shadow:none">
  </section>

  <section>
   <h2>Simple Network</h2>
   <img width="829" height="425" src="img/netvis-mnist-100S_829x425.png" alt="Multi-Layer" style="border:none;box-shadow:none">
   <p><i>... around 2-3% error rate on the test set</i></p>
  </section>
  
  <section>
   <h2>Workshop : MNIST</h2>
   <ul class="fix-spacing">
    <li>Go to : <code>http://ConvNetJS.com/</code></li>
    <li>Look for : "Classify MNIST"</li>
    <li><i>... CNN approach (rather than MLP)</i></li>
   </ul>
   <img width="473" height="444" src="img/ConvNetJS-MNIST_473x444.png" alt="ConvNetJS MNIST" style="border:none;box-shadow:none">
  </section>

  <section>
   <h2>"LeNet"</h2>
   <img width="759" height="209" src="img/lenet5_759x209.png" alt="LeNet5 Convolutional Layers" style="border:none;box-shadow:none">
   <p><i>... around 0.8% error rate on the test set</i></p>
  </section>
</section>
!-->

<section hidden="" class="stack future" style="top: 0px; display: block;">
  <section style="top: -308px; display: block;">
   <h2>Image Classification</h2>
   <br>
   <img width="850" height="314" src="./images/ilsvrc1_850x314.png" alt="ImageNet Karpathy" style="border:none;box-shadow:none">
   <p>In 2012, Deep Learning started to beat other approaches...</p>
  </section>

  <section class="future" style="top: -309.5px; display: block;">
   <h2>What is a CNN?</h2>
   <ul class="fix-spacing">
    <li>Pixels in an images are 'organised' : </li>
    <li style="list-style-type:none">
      <ul>
        <li>Up/down left/right</li>
        <li>Translational invariance</li>
      </ul>
    </li>
    <li>Idea : Use whole image as feature</li>
    <li style="list-style-type:none">
      <ul>
        <li>Update parameters of 'Photoshop filters'</li>
      </ul>
    </li>
    <li>Mathematical term : 'convolution kernel'</li>
    <li style="list-style-type:none">
      <ul>
        <li>CNN = Convolutional Neural Network</li>
      </ul>
    </li>
   </ul>
  </section>
  
  <section >
   <h2>CNN Filter</h2>
   <img width="464" height="358" src="./images/CNN-diagram_464x358.png" alt="CNN Diagram" style="border:none;box-shadow:none">
  </section>

  <section >
   <h2>Play with a Filter</h2>
   <img width="600" height="452" src="./images/CNN-demo_600x452.png" alt="Convolution Demo" style="border:none;box-shadow:none">
  </section>

  <section >
   <h2>CNN Flow</h2>
   <img width="800" height="383" src="./images/CNN-car-to-label_800x383.png" alt="CNN flow" style="border:none;box-shadow:none">
  </section>
</section>


<section hidden="" class="stack future" style="top: 0px; display: block;">
  <section style="top: -350px; display: block;">
   <h2>Image Competition</h2>
   <ul class="fix-spacing">
    <li>ImageNet aka ILSVRC</li>
    <li>over 15 million labeled high-resolution images...</li>
    <li style="list-style-type:none"> ... in over 22,000 categories</li>
   </ul>
   <br>
   <img width="850" height="314" src="./images/ilsvrc1_850x314.png" alt="ImageNet Karpathy" style="border:none;box-shadow:none">
  </section>

  <section >
   <h2>More Complex Networks</h2>
   <img width="614" height="286" src="./images/googlenet-arch_1228x573.jpg" alt="Google ImageNet" style="border:none;box-shadow:none">
   <p><i>GoogLeNet (2014)</i></p>
  </section>
  
  <section >
   <h2>3-ImageNet-googlenet</h2>
   <ul class="fix-spacing">
    <li>Play with a pre-trained network</li>
   </ul>
  </section>

</section>


<section hidden="" class="stack future" style="top: -20px; display: none;">
  <section style="top: -20px; display: none;">
   <h2>... Even More Complex</h2>
   <img width="800" height="299" src="./images/inception03_800x299.png" alt="Google Inception v3" style="border:none;box-shadow:none">
   <p><i>Google Inception-v3 (2015)</i></p>
  </section>
  
  <section >
   <h2>... and Deeper</h2>
   <img width="756" height="443" src="./images/RevolutionOfDepth_756x443.png" alt="Revolution of Depth" style="border:none;box-shadow:none">
   <p><i>Microsoft ResNet (2015)</i></p>
  </section>
  
</section>

<section hidden="" class="stack future" style="top: -20px; display: none;">
  <section style="top: -20px; display: none;">
   <h2>More CNNs ?</h2>
   <ul class="fix-spacing">
    <li>Since CNNs are good at images ...</li>
    <li>... make everything into images</li>
   </ul>
  </section>

  <section >
   <h2>Let's Abuse a CNN</h2>
   <ul class="fix-spacing">
    <li>For example : <b>Speech Recognition</b></li>
    <li>Make this into an Image Recognition task</li>
   </ul>
  </section>
  
  <section >
   <h2>Speech Data 'stamps'</h2>
   <img width="484" height="344" src="./images/CNN-for-speech_data_484x344.png" alt="speech/SpeechRecognition_Dat" style="border:none;box-shadow:none">
   <code>'speech/SpeechRecognition_Data.ipynb'</code>
  </section>

  <section >
   <h2>CNN Speech Recognition</h2>
   <ximg width="484" height="344" src="img/CNN-for-speech_data_484x344.png" alt="speech/SpeechRecognition_Dat" style="border:none;box-shadow:none">
    
   <code>'speech/SpeechRecognition_Learn.ipynb'</code>
     
<pre>stamps.shape: (31, 64, 32)
labels.shape: (31,)
batch_input_fn sizing :  (31, 64, 32, 1)

INFO:tensorflow:Starting evaluation at 2017-03-18-04:31:04
INFO:tensorflow:Evaluation [1/1]
INFO:tensorflow:Finished evaluation at 2017-03-18-04:31:05
{'accuracy': 1.0, 'loss': 0.0068151536, 'global_step': 3830}
</pre>
  </ximg></section>
  
</section>


<!--
<section>
  <section>
   <h2>5-Commerce</h2>
   <ul class="fix-spacing">
    <li></li>
   </ul>
   <ximg width="473" height="444" src="img/ConvNetJS-MNIST_473x444.png" alt="ConvNetJS MNIST" style="border:none;box-shadow:none">
  </section>
</section>

<section>
  <section>
   <h2>6-Visual-Art</h2>
   <ul class="fix-spacing">
    <li></li>
   </ul>
   <ximg width="473" height="444" src="img/ConvNetJS-MNIST_473x444.png" alt="ConvNetJS MNIST" style="border:none;box-shadow:none">
  </section>
</section>
!-->

<!--
<section>
  <section>
   <h2>LSTM Units</h2>
   <img width="412" height="470" src="img/LSTM_412x470.png" alt="LSTM" style="border:none;box-shadow:none">
  </section>

  <section>
   <h2>8-Natural-Language</h2>
   <ul class="fix-spacing">
    <li></li>
   </ul>
   <ximg width="473" height="444" src="img/ConvNetJS-MNIST_473x444.png" alt="ConvNetJS MNIST" style="border:none;box-shadow:none">
  </section>

  <section>
   <h2>Poetry : Epoch 1</h2>
   <pre><code data-trim contenteditable>
JDa&amp;g#sdWI&amp;MKW^gE)I}&amp;lt;UNK>f;6g)^5*|dXdBw6m\2&amp;XcXVy\ph8G&amp;lt;gAM&amp;>e4+mv5}OX8G*Yw9&amp;n3XW{h@&amp;T\Fk%BPMMI
OV&amp;*C_] ._f$v4I~$@Z^&amp;[2
mOVe`4W)"L-KClkO]wu]\$LCNadyo$h;>$jV7X$XK#4,T(y"sa6W0LWf\'_{\#XD]p%ck[;O`!Px\#E>/Or(.YZ|a]2}q|@a9.g3nV,U^qM	$+:nlk0sd;V-Z&amp;;7Y@Z "l-7P^C
"xBF~~{n} n\ Pcbc9f?=y)FIc1h5kvjIi
C&amp;lt;UNK>s	DWJr_$ZQtu"BTYm'|SMj-]Z&amp;lt;Vqj*.lh%IYW|q.GK:eNI"r>833?+RuUsOj_)a{\T}gH.zZR^(daC3mg5P0iFi]bqGo4?T|\>0_H&amp;g889voTh=~)^DDRYND46z1J]x;&amp;lt;U>>%eNIRckL)N8n&amp;lt;UNK>n3i)+Ln8
?)9.#s7X]}$*sxZ"3tf ")
@'HW.;I5)C.*%}&amp;lt;jcNLN+Z__RWoryOb#
/`r
   </code></pre>
  </section>
  
  <section>
   <h2>Poetry : Epoch 100</h2>
   <pre><code data-trim contenteditable>
Som the riscele his nreing the timest stordor hep pIs dach suedests her, so for farmauteds?
By arnouy ig wore
Thou hoasul dove he five grom ays he bare as bleen,
The seend,
And, an neeer,
Whis with the rauk with, for be collenss ore his son froven faredure:
Then andy bround'd the CowE nom shmlls everom thoy men ellone per in the lave ofpen the way ghiind, thour eyes in is ple gull heart sind, I I wild,
Frreasuce anspeve, wrom fant beiver, not the afan
And in thou' histwish a it wheme-tis lating ble the liveculd;
Noorroint he fhallought, othelts.
   </code></pre>
  </section>
  
  <section>
   <h2>Poetry : Epoch 1000</h2>
   <pre><code data-trim contenteditable>
AWhis grook my glass' to his sweet,
Bub my fears liken?
And of live every in seedher;
A Lood stall,
But tare tought than thencer sud earth,
Use'st bee sechion,
For all exprit' are a daud in heaven doth her infook perust the fork the tent.

For maud,
The pittent gover
This and rimp,
Who new
  
Thoir oldes and did hards, cound.
   </code></pre>
  </section>
  
  <section>
   <h2>Plays : Epoch 338</h2>
   <h3>Larger network...</h3>
   <pre><code data-trim contenteditable>
DEDENIUS	Why shoulmeying to to wife,
	And thou say: and wall you teading for
	that struke you down as sweet one.
	With be more bornow, bly unjout on the account:
	I duked you did four conlian unfortuned drausing-
	to sicgia stranss, or not sleepplins his arms
	Gentlemen? as write lord; gave sold.

AENEMUUNS	Met that will knop unhian, where ever have
	of the keep his jangst?icks he I love hide,
	Jach heard which offen, sir!'

	[Exit PATIIUS, MARGARUS arr	[Enter CLOTHUR]
   </code></pre>
  </section>

</section>

<section>

  <section>
   <h2>Image Labelling</h2>
   <img width="642" height="484" src="img/image-labelling_642x484.png" alt="Image Labelling" style="border:none;box-shadow:none">
  </section>

  <section>
   <h2>Image Labels</h2>
   <img width="667" height="419" src="img/image-labelling-results_667x419.png" alt="Labelling Results" style="border:none;box-shadow:none">
  </section>
  
</section>
!-->

<!--
<section>
 <h2>"A.I. Effect"</h2>
 <ul class="fix-spacing">
  <li><a href="https://en.wikipedia.org/wiki/AI_effect" target="_blank">A.I. is whatever hasn't been done yet</a></li>
 </ul>
</section>
!-->


<section hidden="" class="future" style="top: -337.5px; display: none;">
 <h2>Wrap-up</h2>
 <ul class="fix-spacing">
  <li>Deep Learning may deserve some hype...</li>
  <li>Field is advancing very rapidly</li>
  <li>Having a GPU is VERY helpful</li>
 </ul>

</section>


<section hidden="" class="future" style="top: -270.5px; display: none;">
 <h1>- پرسش؟ -</h1>
 <br>
 m.amintoosi @ gmail.com
 <br>
 <p>صفحه شخصی : <a href="http://mamintoosi.ir/">http://mamintoosi.ir</a></p>
 <p>صفحه من در گیت‌هاب : <a href="https://mamintoosi.github.io/">http://mamintoosi.github.io</a></p>
 <p>گیت‌هاب : <a href="https://github.com/mamintoosi">mamintoosi</a></p>
 <hr>
 <h6>
 <p> مطالب و سبک اسلاید برگرفته از 
	<a href="https://github.com/mdda/deep-learning-workshop"> Martin Andrews </a>
	و
	<a href="https://hameds.github.io/slides/"> سعیدی‌فرد </a>
 </p>
 </h6>
 
</section>	

</div>

</div>

<script src="../../js/reveal.js"></script>

<script>

// More info https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
	controls: true,
	progress: true,
	center: true,
	hash: true,

	transition: 'slide', // none/fade/slide/convex/concave/zoom

	// More info https://github.com/hakimel/reveal.js#dependencies
	dependencies: [
		{ src: '../../plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
		{ src: '../../plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
		{ src: '../../plugin/highlight/highlight.js', async: true },
		{ src: '../../plugin/search/search.js', async: true },
		{ src: '../../plugin/zoom-js/zoom.js', async: true },
		{ src: '../../plugin/notes/notes.js', async: true }
	]
});

</script>

</body>
</html>
